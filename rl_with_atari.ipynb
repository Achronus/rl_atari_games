{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed87b53b-9602-4c27-ba3f-d9d40ff4279a",
   "metadata": {},
   "source": [
    "# Reinforcement Learning with Atari Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f54684c-c9be-408c-9f1d-9c7d1228d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents.ppo import PPO\n",
    "from core.parameters import (\n",
    "    EnvParameters,\n",
    "    DQNParameters,\n",
    "    PPOParameters,\n",
    "    ModelParameters\n",
    ")\n",
    "from core.env_details import EnvDetails\n",
    "from agents.dqn import DQN\n",
    "from models.actor_critic import ActorCritic\n",
    "from models.cnn import CNNModel\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a621639-4192-4fce-895e-14b335bfe7ff",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ce200a-32d4-4282-8221-2c92fe7fe458",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create access to .env file (hyperparameters)\n",
    "load_dotenv()\n",
    "\n",
    "SEED = int(os.getenv('SEED'))\n",
    "LEARNING_RATE = float(os.getenv('LEARNING_RATE'))\n",
    "EPSILON = float(os.getenv('EPSILON'))\n",
    "NUM_EPISODES = int(os.getenv('NUM_EPISODES'))\n",
    "SAVE_EVERY = int(os.getenv('SAVE_EVERY'))\n",
    "CAPTURE_VIDEO = True if os.getenv('CAPTURE_VIDEO') == 'True' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c724c7a-2e0f-4b31-a09b-92fa2d71da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10b0e77-fd3e-437c-8236-138672df4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = EnvParameters(\n",
    "    env_name=os.getenv('ENV_1'),\n",
    "    img_size=int(os.getenv('IMG_SIZE')),\n",
    "    stack_size=int(os.getenv('STACK_SIZE')),\n",
    "    capture_video=CAPTURE_VIDEO,\n",
    "    record_every=SAVE_EVERY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730bb0b5-0f99-430a-887e-5b2f0e845b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Frazzle\\anaconda3\\envs\\rla2\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env_details = EnvDetails(env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afeba61b-fb5e-415a-8d3c-738ca6c3d5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gym_name': 'ALE/SpaceInvaders-v5', 'name': 'SpaceInvaders', 'obs_space': Box(0, 255, (4, 128, 128), uint8), 'action_space': Discrete(6), 'input_shape': (4, 128, 128), 'n_actions': 6, 'img_size': 128, 'stack_size': 4, 'capture_video': False, 'record_every': 1000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63c80-1fd1-4579-b18a-d5fa6c20f1a0",
   "metadata": {},
   "source": [
    "## 2. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60affa60-f650-4b74-89de-d59f8a6b7b04",
   "metadata": {},
   "source": [
    "### 2a. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e017354-4c32-4a70-9488-2468c9834b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DQN hyperparameters\n",
    "network = CNNModel(input_shape=env_details.input_shape, n_actions=env_details.n_actions)\n",
    "\n",
    "dqn_model_params = ModelParameters(\n",
    "    network=network,\n",
    "    optimizer=optim.Adam(network.parameters(), lr=LEARNING_RATE, eps=EPSILON),\n",
    "    loss_metric=nn.MSELoss()\n",
    ")\n",
    "\n",
    "dqn_params = DQNParameters(\n",
    "    gamma=float(os.getenv('GAMMA')),\n",
    "    tau=float(os.getenv('TAU')),\n",
    "    buffer_size=int(float(os.getenv('BUFFER_SIZE'))),\n",
    "    batch_size=int(os.getenv('BATCH_SIZE')),\n",
    "    update_steps=int(os.getenv('UPDATE_STEPS')),\n",
    "    eps_start=float(os.getenv('EPS_START')),\n",
    "    eps_end=float(os.getenv('EPS_END')),\n",
    "    eps_decay=float(os.getenv('EPS_DECAY')),\n",
    "    max_timesteps=int(os.getenv('MAX_TIMESTEPS'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725535d6-9d22-4398-85fc-0ffb43650a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Create DQN instance\n",
    "dqn = DQN(env_details, dqn_model_params, dqn_params, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f681e4b3-54d7-4fc8-91a3-69a7162f1f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "# dqn.train(num_episodes=3, print_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76989e54-1c8d-47e2-b1b6-371b6f9cb4d5",
   "metadata": {},
   "source": [
    "### 2b. Proximal Policy Optimization (PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd61636d-5666-45c7-b91f-73aa7a993856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PPO hyperparameters\n",
    "actor_critic = ActorCritic(input_shape=env_details.input_shape, n_actions=env_details.n_actions)\n",
    "\n",
    "ppo_model_params = ModelParameters(\n",
    "    network=actor_critic,\n",
    "    optimizer=optim.Adam(actor_critic.parameters(), lr=LEARNING_RATE, eps=EPSILON),\n",
    "    loss_metric=nn.MSELoss()\n",
    ")\n",
    "\n",
    "ppo_params = PPOParameters(\n",
    "    gamma=float(os.getenv('GAMMA')),\n",
    "    update_steps=int(os.getenv('UPDATE_STEPS')),\n",
    "    clip_grad=float(os.getenv('CLIP_GRAD')),\n",
    "    rollout_size=int(os.getenv('ROLLOUT_SIZE')),\n",
    "    num_agents=int(os.getenv('NUM_AGENTS')),\n",
    "    num_mini_batches=int(os.getenv('NUM_MINI_BATCHES')),\n",
    "    entropy_coef=float(os.getenv('ENTROPY_COEF')),\n",
    "    value_loss_coef=float(os.getenv('VALUE_LOSS_COEF')),\n",
    "    max_grad_norm=float(os.getenv('MAX_GRAD_NORM'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b051aab5-79eb-42d2-8054-4384c256843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Create PPO instance\n",
    "ppo = PPO(env_details, ppo_model_params, ppo_params, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8abb2ea0-35ba-451c-8ec8-329016b0e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c4a6b2-2326-4ee8-9aad-050683f743e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent on SpaceInvaders with 240 episodes.\n",
      "Gradient clip size: 0.1, rollout size: 10, num_agents: 8, network updates: 4, batch size: 80, training iterations: 3.\n",
      "(1/3) Episodic Return: 0.01499,  Approx KL: 0.00828,  Total Loss: -0.03070,  Policy Loss: -0.01284,  Value Loss: 0.00001,  Entropy Loss: 1.78657\n",
      "(2/3) Episodic Return: 0.02089,  Approx KL: -0.01420,  Total Loss: -0.06547,  Policy Loss: -0.04787,  Value Loss: 0.00006,  Entropy Loss: 1.76285\n",
      "(3/3) Episodic Return: 0.02174,  Approx KL: 1.68957,  Total Loss: -0.32796,  Policy Loss: -0.31982,  Value Loss: 0.00031,  Entropy Loss: 0.82958\n",
      "Training complete. Access metrics from 'logger' attribute.\n"
     ]
    }
   ],
   "source": [
    "ppo.train(num_episodes=240, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac281a-128b-474d-962f-580b1a400bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rla2",
   "language": "python",
   "name": "rla2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
