{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed87b53b-9602-4c27-ba3f-d9d40ff4279a",
   "metadata": {},
   "source": [
    "# Reinforcement Learning with Atari Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a621639-4192-4fce-895e-14b335bfe7ff",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9380453d-9c2b-41fb-b9f3-b7d739143812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from core.create import create_model, set_save_every\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4292c565-0b2d-45ed-98bf-4b43d7cb5824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_EPISODES=10000, SAVE_EVERY=1000\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Create access to .env file\n",
    "\n",
    "NUM_EPISODES = int(os.getenv('NUM_EPISODES'))\n",
    "PPO_NUM_EPISODES = int(os.getenv('ROLLOUT_SIZE')) * int(os.getenv('NUM_AGENTS')) * NUM_EPISODES\n",
    "SAVE_EVERY = set_save_every(1000)\n",
    "print(f'NUM_EPISODES={NUM_EPISODES}, SAVE_EVERY={SAVE_EVERY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90f4e46-4395-450c-ac79-dd4a8e6ee12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Frazzle\\anaconda3\\envs\\rla2\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "rainbow = create_model('rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eabe164-3fc3-4ccb-ac75-463ff566de4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent on SpaceInvaders with 4 episodes.\n",
      "Buffer size: 1k, batch size: 32, max timesteps: 1k, num network updates: 4, replay period: 100.\n",
      "(1/4)  Episode Score: 120,   Train Loss: 3.92731,  Time taken: 7.86 secs.\n",
      "(3/4)  Episode Score: 140,   Train Loss: 3.30087,  Time taken: 19.36 secs.\n",
      "(4/4)  Episode Score: 155,   Train Loss: 3.18888,  Time taken: 11.25 secs.\n",
      "Training complete. Access metrics from 'logger' attribute. "
     ]
    }
   ],
   "source": [
    "rainbow.train(num_episodes=4, print_every=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6178416d-2a18-4757-81b7-90d83789ec4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gym_name': 'ALE/SpaceInvaders-v5', 'name': 'SpaceInvaders', 'obs_space': Box(0, 255, (4, 128, 128), uint8), 'action_space': Discrete(6), 'input_shape': (4, 128, 128), 'n_actions': 6, 'img_size': 128, 'stack_size': 4, 'capture_video': False, 'record_every': 1000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainbow.env_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63c80-1fd1-4579-b18a-d5fa6c20f1a0",
   "metadata": {},
   "source": [
    "## 2. Model Creation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60affa60-f650-4b74-89de-d59f8a6b7b04",
   "metadata": {},
   "source": [
    "### 2a. Rainbow Deep Q-Network (RDQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725535d6-9d22-4398-85fc-0ffb43650a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Create Rainbow DQN instance\n",
    "dqn = create_model('rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aad46cd-adc2-4828-b283-2cd7fc2fbc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gym_name': 'ALE/SpaceInvaders-v5', 'name': 'SpaceInvaders', 'obs_space': Box(0, 255, (4, 128, 128), uint8), 'action_space': Discrete(6), 'input_shape': (4, 128, 128), 'n_actions': 6, 'img_size': 128, 'stack_size': 4, 'capture_video': False, 'record_every': 1000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.env_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f681e4b3-54d7-4fc8-91a3-69a7162f1f54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent on SpaceInvaders with 4 episodes.\n",
      "Buffer size: 1k, batch size: 32, max timesteps: 1k, num network updates: 4, replay period: 100.\n",
      "(1/4)  Episode Score: 120,   Train Loss: 3.92731,  Time taken: 5.69 secs.\n",
      "(2/4)  Episode Score: 120,   Train Loss: 3.59958,  Time taken: 9.68 secs.\n",
      "(3/4)  Episode Score: 110,   Train Loss: 3.30087,  Time taken: 9.67 secs.\n",
      "(4/4)  Episode Score: 100,   Train Loss: 3.18888,  Time taken: 6.05 secs.\n",
      "Training complete. Access metrics from 'logger' attribute. "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "dqn.train(num_episodes=4, print_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76989e54-1c8d-47e2-b1b6-371b6f9cb4d5",
   "metadata": {},
   "source": [
    "### 2b. Proximal Policy Optimization (PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b051aab5-79eb-42d2-8054-4384c256843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device set to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Create PPO instance\n",
    "ppo = create_model('ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8ae064-8fab-40ae-a0df-e1f20de41e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gym_name': 'ALE/SpaceInvaders-v5', 'name': 'SpaceInvaders', 'obs_space': Box(0, 255, (4, 128, 128), uint8), 'action_space': Discrete(6), 'input_shape': (4, 128, 128), 'n_actions': 6, 'img_size': 128, 'stack_size': 4, 'capture_video': False, 'record_every': 1000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.env_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c4a6b2-2326-4ee8-9aad-050683f743e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0bec5f-9f1d-4402-97ba-985fa47d3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_episodes = int((PPO_NUM_EPISODES / NUM_EPISODES) * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ac281a-128b-474d-962f-580b1a400bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent on SpaceInvaders with 3K episodes.\n",
      "Surrogate clipping size: 0.1, rollout size: 100, num agents: 8, num network updates: 4, batch size: 800, training iterations: 4.\n",
      "(1/4) Episodic Return: 0.65218,  Approx KL: -0.00013,  Total Loss: 0.16497,  Policy Loss: -0.00235,  Value Loss: 0.37043,  Entropy Loss: 1.78998,  Time taken: 1.69 secs.\n",
      "(2/4) Episodic Return: 0.71180,  Approx KL: -0.00021,  Total Loss: 0.10673,  Policy Loss: -0.01412,  Value Loss: 0.27722,  Entropy Loss: 1.77619,  Time taken: 1.49 secs.\n",
      "(3/4) Episodic Return: 0.56792,  Approx KL: 2.44697,  Total Loss: -0.29434,  Policy Loss: -0.36546,  Value Loss: 0.15562,  Entropy Loss: 0.66896,  Time taken: 1.53 secs.\n",
      "(4/4) Episodic Return: 0.13229,  Approx KL: -0.00001,  Total Loss: 0.00239,  Policy Loss: 0.00000,  Value Loss: 0.00477,  Entropy Loss: 0.00001,  Time taken: 1.50 secs.\n",
      "Training complete. Access metrics from 'logger' attribute. "
     ]
    }
   ],
   "source": [
    "ppo.train(num_episodes=demo_episodes, print_every=1)  # 4 training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488a0a7-e463-4ecf-852b-8f522434a918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rla2",
   "language": "python",
   "name": "rla2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
